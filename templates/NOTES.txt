1. Get the application URL by running these commands:
{{- if .Values.ingress.enabled }}
{{- range $host := .Values.ingress.hosts }}
  {{- range .paths }}
  http{{ if $.Values.ingress.tls }}s{{ end }}://{{ $host.host }}{{ .path }}
  {{- end }}
{{- end }}
{{- else if contains "NodePort" .Values.service.type }}
  export NODE_PORT=$(kubectl get --namespace {{ .Release.Namespace }} -o jsonpath="{.spec.ports[0].nodePort}" services {{ include "cgwi-php.fullname" . }})
  export NODE_IP=$(kubectl get nodes --namespace {{ .Release.Namespace }} -o jsonpath="{.items[0].status.addresses[0].address}")
  echo http://$NODE_IP:$NODE_PORT
{{- else if contains "LoadBalancer" .Values.service.type }}
     NOTE: It may take a few minutes for the LoadBalancer IP to be available.
           You can watch the status of by running 'kubectl get --namespace {{ .Release.Namespace }} svc -w {{ include "cgwi-php.fullname" . }}'
  export SERVICE_IP=$(kubectl get svc --namespace {{ .Release.Namespace }} {{ include "cgwi-php.fullname" . }} --template "{{"{{ range (index .status.loadBalancer.ingress 0) }}{{.}}{{ end }}"}}")
  echo http://$SERVICE_IP:{{ .Values.service.port }}
{{- else if contains "ClusterIP" .Values.service.type }}
  export POD_NAME=$(kubectl get pods --namespace {{ .Release.Namespace }} -l "app.kubernetes.io/name={{ include "cgwi-php.name" . }},app.kubernetes.io/instance={{ .Release.Name }}" -o jsonpath="{.items[0].metadata.name}")
  export CONTAINER_PORT=$(kubectl get pod --namespace {{ .Release.Namespace }} $POD_NAME -o jsonpath="{.spec.containers[0].ports[0].containerPort}")
  echo "Visit http://127.0.0.1:8080 to use your application"
  kubectl --namespace {{ .Release.Namespace }} port-forward $POD_NAME 8080:$CONTAINER_PORT
{{- end }}

2. Initial setup (population of persistent volumes):
  After first helm install, the app will not be running (and in fact, neither the mysql database nor the app directory
  will contain anything useful).

  There is a cronjob (cj/clone-and-compose-{{ include "cgwi-php.fullname" . }}) which is set to suspend, that performs
  `git clone` (or subsequent `git pull`), then `composer install` in the `/srv/app` directory mounted in the relevant pvc.

  You can manually create a one-off batch job from this cj as a template:
    kubectl create job --from=cronjob/clone-and-compose-{{ include "cgwi-php.fullname" . }} initialize-{{ include "cgwi-php.fullname" . }}-$(date '+%Y%m%d-%H%M') --dry-run=client -o json | jq '.metadata |= (del(.ownerReferences))' | kubectl apply -f -

  (this requires jq for now as a workaround to a kubernetes/openshift issue creating jobs from cronjobs)

  If doing a new install with existing data, you'll also want to populate the `/app/srv/storage` directory (TODO docs) and the
  mysql database as described in item #3 below.

  As the last step, you will need to "scale-up" the statefulset for the app:
    kubectl scale --replicas=1 sts/{{ include "cgwi-php.fullname" . }}

3. To load a prior database from a local mysqldump-ed database (in $MYSQL_DATABASE.sql.gz, for instance):
  gzip -dc $MYSQL_DATABASE.sql.gz | kubectl exec -i svc/{{ include "cgwi-php.fullname" . }}-mysql -- bash -c 'MYSQL_PWD=$MYSQL_PASSWORD mysql -u $MYSQL_USER $MYSQL_DATABASE'

4. Obtaining a database backup:
  Backups are stored in the persistent-volume-claim backups-{{ include "cgwi-php.fullname" . }} (from relevant cronjob).
  K8S does not make it trivial to get get files from intermittently-attached PVCs, though, so to get a one-off backup:

  kubectl exec svc/{{ include "cgwi-php.fullname" . }}-mysql -- bash -c 'MYSQL_PWD=$MYSQL_ROOT_PASSWORD mysqldump -u root --quick --comments --dump-date --lock-all-tables --column-statistics=0 --flush-privileges --flush-logs $MYSQL_DATABASE'

  This will write to stdout. You will probably want to pipe/redirect this...
